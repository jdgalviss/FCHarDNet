model:
    arch: hardnet
data:
    dataset: tempest
    train_split: train
    val_split: val
    img_rows: 316
    img_cols: 706
    path: /data/Tempest/
    sbd_path: /data/Tempest/
training:
    train_iters: 90000
    batch_size: 16
    val_interval: 500
    n_workers: 8
    print_interval: 10
    augmentations:
        hflip: 0.5
    optimizer:
        name: 'sgd'
        lr: 0.02
        weight_decay: 0.0005
        momentum: 0.9
    loss:
        name: 'bootstrapped_cross_entropy'
        min_K: 4096
        loss_th: 0.3
        size_average: True
    lr_schedule: 
        name: 'poly_lr'
        max_iter: 90000
    resume: None
    finetune: None    
